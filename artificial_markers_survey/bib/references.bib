
@inproceedings{fiala2005artag,
  abstract = {Fiducial marker systems consist of patterns that are
mounted in the environment and automatically detected in
digital camera images using an accompanying detection
algorithm. They are useful for Augmented Reality (AR),
robot navigation, and general applications where the relative pose between a camera and object is required. Important parameters for such marker systems is their false
detection rate (false positive rate), their inter-marker confusion rate, minimal detection size (in pixels) and immunity
to lighting variation. ARTag is a marker system that uses
digital coding theory to get a very low false positive and
inter-marker confusion rate with a small required marker
size, employing an edge linking method to give robust lighting variation immunity. ARTag markers are bi-tonal planar
patterns containing a unique ID number encoded with robust digital techniques of checksums and forward error correction (FEC). This proposed new system, ARTag has very
low and numerically quantifiable error rates, does not require a greyscale threshold as does other marker systems,
and can encode up to 2002 different unique ID’s with no
need to store patterns. Experimental results are shown validating this system.},
  title={ARTag, a fiducial marker system using digital techniques},
  author={Fiala, Mark},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
  volume={2},
  pages={590--596},
  year={2005},
  organization={IEEE},
  keywords = { Robustness:Lightness, Robustness:Occlusion,Robustness:Reflectance}
}

@article{kabuka1987position,
  title={Position verification of a mobile robot using standard pattern},
  author={Kabuka, Mansur and Arenas, A},
  journal={IEEE Journal on Robotics and Automation},
  volume={3},
  number={6},
  pages={505--516},
  year={1987},
  publisher={IEEE},
  abstract = {s mobile robots are taking on more and more of the tasks
that were normally delegated to humans, they need to acquire higher
degrees of autonomous operation, which calls for accurate and efficient
position determination and/or verification. The critical geometricdimensions of a standard pattern are used hereto locate the relative position of
the mobile robot with respectto the pattern; bydoing so, the method does
not depend on values of any intrinsic camera parameters, except the focal
length. In addition, this method has the advantages of simplicity and
flexibility. This standard patternis also provided witha unique identification code, using bar codes, that enables the system to find the absolute
location of the pattern. These bar codes also assist in the scanning
algorithms to locate the pattern in the environment. A thorough error
analysis and experimental results obtained through software simulation
are presented, as well as the current direction of our work.},
  keywords = {Robustness:Difficult angle,Robustness:Distance }
}
@inproceedings{o1990subpixel,
  title={Subpixel registration using a concentric ring fiducial},
  author={O'Gorman, Lawrence and Bruckstein, Alfred M and Bose, Chinmoy B and Amir, Israel},
  booktitle={[1990] Proceedings. 10th International Conference on Pattern Recognition},
  volume={2},
  pages={249--253},
  year={1990},
  organization={IEEE}
  ,
  abstract = {One way to perfarm registration and alignment for machine
assembly is with re.spcc3 to precisely located landmulrs,
called fidud.lr, that ue located by machine vision means.
For appliahns N& as electronics rssanbly. where densitiu
ue high and tolerances must be low. the pnCision by which
the fiducials ue located affects everything aligned relative to
them. We examine the effeas of spatial sampling and image
mise on the preciaion by which the centroids of different
geometric shapes can be determined. The cancentric ring
fiducial - a bull'scye pattem - is identified as having
desirable qualities of high location precision and rotational
invariance. The pefiormance of the cancentric fiducial. as a
function of diameter. number of rings. and ring spacing. has
beentested, and these results are shown.},
  keywords = {Robustness :  Noise}
}
@inproceedings{gatrell1992robust,
  title={Robust image features: Concentric contrasting circles and their image extraction},
  author={Gatrell, Lance B and Hoff, William A and Sklair, Cheryl W},
  booktitle={Cooperative Intelligent Robotics in Space II},
  volume={1612},
  pages={235--244},
  year={1992},
  organization={SPIE}
  ,
  abstract = {Many comput& vision tasks can be simplified if special image featies &e placed on the objects to be recognized. A review
of special image featwes that have been used in the st is given, aM then a tw image feature, the Concentrie Contrasting
Circle, is iwesen$ed. The Concentrie Contrasting Circle image feature has the advantages that it can be easily manuftured, it
is easily extracted from the image, its extrtion is robust (true targets are found, while few false targets are found), it is a
_ve feature, aid its centroid is completely invariant to the three translational and one rotational degrees of fieekxn and
nexly invariant k the remaining two rotational degrees of freeckxn. There &e seva1 examples of existing parallel
iinpIcinetations which perfonn most of the extration wwk. Extrtion robustness was measured by recording the
abi1ity of correct detection and the false alarm rate in a set of images of sceis containing mockups of sdllites, fluid
cings, and electrical component& A typieal application ofConcentric Contrasting Circle features is to pI&e them on
modeled objects f monocular pose estimation thject identifleation. This feature is demonstrated on a visually
challenging b:kgrowxI of a specular but wrinkled surfe similar to a Multi4ayered Insulation spacecraft thermal blanket.},
  keywords = {Robustness :  Lightness}
}

@inproceedings{cho1998multi,
  title={A multi-ring color fiducial system and an intensity-invariant detection method for scalable fiducial-tracking augmented reality},
  author={Cho, Youngkwan and Lee, Jongweon and Neumann, Ulrich},
  booktitle={In IWAR},
  year={1998},
  organization={Citeseer}
  ,
  abstract = {In Augmented Reality (AR), a user can see a virtual world as well as a real
world. To avoid the registration problem between the virtual world and the real
world, the user’s pose in both worlds should be exactly the same. Fiducial
tracking AR is an attractive approach to the registration problem, but most of
the developed fiducial tracking AR systems have very limited tracking ranges
and require carefully prepared environments, especially lighting conditions. To
provide for wide views and detailed views in large-scale applications, an AR
system should have a scalable tracking capability under varying light condition.
In this paper, we propose multi-ring color fiducial systems and a lightinvariant fiducial detection method for scalable fiducial tracking AR systems.
We analyze the optimal ring width, and develop formulas to obtain the optimal
fiducial set with system specific inputs. We present a light-invariant circular
fiducial detection method that uses relations among fiducials and their
backgrounds for segmenting regions of an image. Our work provides a simple
and convenient way to achieve wide-area tracking for AR.},
  keywords = {Robustness :  Lightness}
}
@inproceedings{rekimoto1998matrix,
  title={Matrix: A realtime object identification and registration method for augmented reality},
  author={Rekimoto, Jun},
  booktitle={Proceedings. 3rd Asia Pacific Computer Human Interaction (Cat. No. 98EX110)},
  pages={63--68},
  year={1998},
  organization={IEEE}
  ,
  abstract = {In Augmented Reality (AR), a user can see a virtual world as well as a real
world. To avoid the registration problem between the virtual world and the real
world, the user’s pose in both worlds should be exactly the same. Fiducial
tracking AR is an attractive approach to the registration problem, but most of
the developed fiducial tracking AR systems have very limited tracking ranges
and require carefully prepared environments, especially lighting conditions. To
provide for wide views and detailed views in large-scale applications, an AR
system should have a scalable tracking capability under varying light condition.
In this paper, we propose multi-ring color fiducial systems and a lightinvariant fiducial detection method for scalable fiducial tracking AR systems.
We analyze the optimal ring width, and develop formulas to obtain the optimal
fiducial set with system specific inputs. We present a light-invariant circular
fiducial detection method that uses relations among fiducials and their
backgrounds for segmenting regions of an image. Our work provides a simple
and convenient way to achieve wide-area tracking for AR.},
  keywords = {Robustness :  Lightness}
}
@inproceedings{kato1999marker,
  title={Marker tracking and hmd calibration for a video-based augmented reality conferencing system},
  author={Kato, Hirokazu and Billinghurst, Mark},
  booktitle={Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99)},
  pages={85--94},
  year={1999},
  organization={IEEE},
  abstract = {We describe an augmented reality conferencing system which
uses the overlay of virtual images on the real world. Remote
collaborators are represented on Virtual Monitors which
can be freely positioned about a user in space. Users can
collaboratively view and interact with virtual objects using
a shared virtual whiteboard. This is possible through precise
virtual image registration using fast and accurate computer
vision techniques and HMD calibration. We propose a
method for tracking fiducial markers and a calibration
method for optical see-through HMD based on the marker
tracking.},
  keywords = {Robustness :  Difficult angle ,
		 Robustness :  Distance ,Robustness :  Occlusion}
}
@inproceedings{rekimoto2000cybercode,
  title={CyberCode: designing augmented reality environments with visual tags},
  author={Rekimoto, Jun and Ayatsuka, Yuji},
  booktitle={Proceedings of DARE 2000 on Designing augmented reality environments},
  pages={1--10},
  year={2000},
  abstract = {The CyberCode is a visual tagging system based on a 2Dbarcode technology and provides several features not provided by other tagging systems. CyberCode tags can be
recognized by the low-cost CMOS or CCD cameras found in
more and more mobile devices, and it can also be used to determine the 3D position of the tagged object as well as its ID
number. This paper describes examples of augmented reality applications based on CyberCode, and discusses some key
characteristics of tagging technologies that must be taken into
account when designing augmented reality environments.},
  keywords = { Robustness :  Distance}
}
@inproceedings{naimark2002circular,
  title={Circular data matrix fiducial system and robust image processing for a wearable vision-inertial self-tracker},
  author={Naimark, Leonid and Foxlin, Eric},
  booktitle={Proceedings. International Symposium on Mixed and Augmented Reality},
  pages={27--36},
  year={2002},
  organization={IEEE},
  abstract = {A wearable low-power hybrid vision-inertial tracker has
been demonstrated based on a flexible sensor fusion core
architecture, which allows easy reconfiguration by
plugging-in different kinds of sensors. A particular prototype
implementation consists of one inertial measurement unit
and one outward-looking wide-angle Smart Camera, with a
built-in DSP to run all required image-processing tasks. The
Smart Camera operates on newly designed 2-D bar-coded
fiducials printed on a standard black-and-white printer. The
fiducial design allows having thousands of different codes,
thus enabling uninterrupted tracking throughout a large
building or even a campus at very reasonable cost. The
system operates in various real-world lighting conditions
without any user intervention due to homomorphic image
processing algorithms for extracting fiducials in the
presence of very non-uniform lighting},
  keywords = {Robustness :  Lightness}
}
@article{mendoncca2002trip,
  title={TRIP: A low-cost vision-based location system for ubiquitous computing},
  author={Mendon{\c{c}}a, Paulo RS and Hopper, Andy and others},
  journal={Personal and Ubiquitous Computing},
  volume={6},
  number={3},
  pages={206--219},
  year={2002},
  publisher={Springer},
  abstract = {Sentient Computing provides computers with perception so that they can react and provide assistance to user activities.
Physical spaces are made sentient when they are wired with networks of sensors capturing context data, which is communicated to
computing devices spread through the environment. These devices interpret the information provided and react by performing the actions
expected by the user. Among the types of context information provided by sensors, location has proven to be especially useful. Since
location is an important context that changes whenever the user moves, a reliable location-tracking system is critical to many sentient
applications. However, the sensor technologies used in indoor location tracking are expensive and complex to deploy, configure and
maintain. These factors have prevented a wider adoption of Sentient Computing in our living and working spaces. This paper presents
TRIP, a low-cost and easily deployable vision-based sensor technology addressing these issues. TRIP employs off-the-shelf hardware (lowcost CCD cameras and PCs) and printable 2-D circular markers for entity identification and location. The usability of TRIP is illustrated
through the implementation of several sentient applications.},
  keywords = {Robustness :  Lightness,Robustness :  Distance }
}
@inproceedings{zhang2002visual,
  title={Visual marker detection and decoding in ar systems: A comparative study},
  author={Zhang, Xiang and Fronz, Stephan and Navab, Nassir},
  booktitle={Proceedings. International Symposium on Mixed and Augmented Reality},
  pages={97--106},
  year={2002},
  organization={IEEE},
  abstract = {Visual markers are widely used in existing augmented
reality (AR) applications [7, 12, 11, 19].In most of such
applications, the performance of an AR system depends
highly on the tracking system for visual marker detection,
tracking, and pose estimation.Currently, there are more
than one marker based tracking/calibration systems available.It is thus desirable for the user to know which marker
tracking system is likely to perform the best for a specific AR application.To this purpose, we compare several marker systems all using planar square coded visual
markers.We present the evaluation results, both qualitatively and quantitatively, for the following properties: the
usability, efficiency, accuracy, and reliability.For a
particular AR application, there are different marker detection and tracking requirements.Therefore, the purpose
of this work is not to rank the existing marker systems; instead, we try to analyze the strength and weakness of various aspects of the marker tracking systems and provide the
AR application developers with this information.},
  keywords = {Robustness :  Out-of-focus Blur ,Robustness :  Lightness,Robustness :  Radial distortion}
}

@article{costanza2003region,
  title={A Region Adjacency Tree Approach to the Detection and Design of Fiducials.},
  author={Costanza, Enrico and Robinson, John},
  year={2003},
  abstract = {We report a topological approach to fiducial recognition for real-time applications.
Independence from geometry makes the system tolerant to severe distortion, and allows
encoding of extra information. The method is based on region adjacency trees. After
describing the mathematical foundations, we present a set of simulations to evaluate the
algorithm and optimise the fiducial design.},
  keywords = {Robustness :  Deformation ,Robustness :  Lightness }
}
@inproceedings{rohs2004real,
  title={Real-world interaction with camera phones},
  author={Rohs, Michael},
  booktitle={International Symposium on Ubiquitious Computing Systems},
  pages={74--89},
  year={2004},
  organization={Springer},
  abstract = {With the integration of cameras, mobile phones have
evolved into networked personal image capture devices.
Camera-phones can perform image processing tasks on the
device itself and use the result as an additional means of
user input and a source of context data. In this paper we
present a system that turns such phones into mobile sensors for 2-dimensional visual codes. The proposed system induces a code coordinate system and visually detects
phone movements. It also provides the rotation angle and
the amount of tilting of the camera as additional input parameters. These features enable applications such as item
selection and interaction with large-scale displays. With
the code coordinate system, each point in the viewed image
– and therefore arbitrarily shaped areas – can be linked to
specific operations. A single image point can even be associated with multiple information aspects by taking different
rotation and tilting angles into account.},
  keywords = {Robustness :  Lightness,Robustness :  Radial distortion}
}
@inproceedings{claus2004reliable,
  title={Reliable fiducial detection in natural scenes},
  author={Claus, David and Fitzgibbon, Andrew W},
  booktitle={European Conference on Computer Vision},
  pages={469--480},
  year={2004},
  organization={Springer},
  abstract = {Reliable detection of fiducial targets in real-world images is
addressed in this paper. We show that even the best existing schemes are
fragile when exposed to other than laboratory imaging conditions, and
introduce an approach which delivers significant improvements in reliability at moderate computational cost. The key to these improvements
is in the use of machine learning techniques, which have recently shown
impressive results for the general object detection problem, for example
in face detection. Although fiducial detection is an apparently simple
special case, this paper shows why robustness to lighting, scale and foreshortening can be addressed within the machine learning framework with
greater reliability than previous, more ad-hoc, fiducial detection schemes.},
  keywords = {Robustness :  Motion Blur,Robustness :  Distance,Robustness :  Lightness}
}


@inproceedings{bencina2005improved,
  abstract = {This paper describes reacTIVision: a camera based two dimensional fiducial (marker) tracking system developed for
the reacTable*, a table based tangible musical instrument.
Key features of reacTIVision include: (1) the ability to track
a large number of fiducials with faster than real-time performance and (2) fiducial size may be varied depending on
the number of distinct fiducial identities required. We describe recent advances in our implementation of topologybased fiducial recognition, including a generalised method
for accurately computing fiducial location and orientation.
A method of graph naming known as left heavy depth sequences is applied to the identification of topologically distinct fiducials. Also discussed is our approach to generating
fiducial images for the system, in which we employ evolutionary computation to produce compact fiducials with specific geometric properties.},
  title={Improved topological fiducial tracking in the reactivision system},
  author={Bencina, Ross and Kaltenbrunner, Martin and Jorda, Sergi},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)-Workshops},
  pages={99--99},
  year={2005},
  organization={IEEE},
   keywords = {Robustness :  Lightness}
}
@inproceedings{dell2005colored,
  title={Colored visual tags: A robust approach for augmented reality},
  author={Dell'Acqua, Andrea and Ferrari, Marco and Marcon, Marco and Sarti, Augusto and Tubaro, Stefano},
  booktitle={IEEE Conference on Advanced Video and Signal Based Surveillance, 2005.},
  pages={423--427},
  year={2005},
  organization={IEEE},
  abstract = {This paper presents a robust method for fast Visual Tags
reading, suitable for Augmented Reality (AR) environments.
Tag detection is based on well known tools of imageprocessing, but their combination, together with the use of
colored markers, allows a robust recognition even with lowcost CMOS or CCD cameras and in poorly illuminated environments. In particular the color mix and the structure of
the tag are quite unusual in common environments and can
be easily detected with color filtering and geometric analysis. The proposed tag carries binary information encoded
in its structure: in the presented implementation a 32-bit
code with 12 parity bits is encoded in the tag but extensions
to longer codes can be easily devised},
  keywords = {Robustness :  Lightness}
}
@article{iso2006iec,
 title={IEC 18004: 2000 Information technology—Automatic identification and data capture techniques—Bar code symbology--QR Code},
  author={ISO, ISO},
  journal={BS ISO/IEC},
  volume={2000},
  year={2000},
  abstract = {Information technology — Automatic
identification and data capture
techniques — Bar code symbology — QR
Code},
  keywords = {}
}
@inproceedings{santos2006ptrack,
  title={Ptrack: Introducing a novel iterative geometric pose estimation for a marker-based single camera tracking system},
  author={Santos, Pedro and Stork, Andre and Buaes, Alexandre and Jorge, Joaquim},
  booktitle={IEEE Virtual Reality Conference (VR 2006)},
  pages={143--150},
  year={2006},
  organization={IEEE},
  abstract = {Inside-out tracking for augmented reality applications
continues to present a challenge in terms of performance,
robustness and accuracy. In particular mobile augmented reality
applications are in need of tracking systems which can be
wearable and do not cause a high processing load. In this paper
we introduce a novel iterative geometric method for pose
estimation from four co-planar points and we present the current
status of PTrack, a marker-based single camera tracking system
benefiting from this approach. The system uses an IDS uEye [1]
camera, equipped with infrared flash strobes and infrared pass
filter, which acquires grayscale images and sends them to a
computer where an image pre-processing algorithm identifies
potential projections of retro-reflective markers. Our novel pose
estimation algorithm identifies possible labels composed of
markers in a 2D post-processing using a divide-and-conquer
strategy to segment the camera's image space and attempts an
iterative geometric 3D reconstruction of position and orientation
in camera space. In the end successfully reconstructed labels are
compared to a database for identification. Their 6 DoF data as
well as their ID is made available to applications through
OpenTracker [2] framework. To assess the performance of our
approach we compared PTrack to ARToolKit [3] - which has
been adapted to work with the same camera - and final results
show that pose estimation is more accurate and precise, in both
translation and rotation.},
  keywords = {Robustness :  Difficult angle,Robustness :  Radial distortion}
}
@article{flohr2007lightweight,
  title={A lightweight ID-based extension for marker tracking systems},
  author={Flohr, Daniel and Fischer, Jan},
  year={2007},
  publisher={The Eurographics Association},
  abstract = {The estimation of the position and orientation of the digital video camera is a central challenge in video seethrough augmented reality. Many augmented reality applications solve this problem with the help of markerbased methods, which analyze artificial fiducials in the images of the real environment, e.g., using the widespread
ARToolKit library. Among the drawbacks of conventional marker tracking is the necessity to manually define
marker patterns. Badly chosen patterns have a negative impact on tracking performance. Although improved
methods for automatic marker generation have been described, manually controlled marker tracking is still widely
used in many applications for practical reasons. In this paper, we describe a lightweight drop-in extension for IDbased marker tracking. Our system makes it possible to automatically generate a large number of tracking fiducials
identified by unique numerical IDs. The created marker patterns consists of large monochrome patches, which
improves the recognition rate and tracking performance compared to typical manually defined fiducials. Due to
the design of our extension, only minimal adaptations are required in order to add ID-based tracking to existing
augmented reality software. We discuss experimental results demonstrating the improved pattern recognition and
describe an example application.},
  keywords = {Robustness :  Lightness , Robustness :  Difficult angle ,Robustness :  Noise }
}
@inproceedings{sattar2007fourier,
  title={Fourier tags: Smoothly degradable fiducial markers for use in human-robot interaction},
  author={Sattar, Junaed and Bourque, Eric and Giguere, Philippe and Dudek, Gregory},
  booktitle={Fourth Canadian Conference on Computer and Robot Vision (CRV'07)},
  pages={165--174},
  year={2007},
  organization={IEEE},
  abstract = {In this paper we introduce the Fourier tag, a synthetic
fiducial marker used to visually encode information and
provide controllable positioning. The Fourier tag is a synthetic target akin to a bar-code that specifies multi-bit information which can be efficiently and robustly detected in an
image. Moreover, the Fourier tag has the beneficial property that the bit string it encodes has variable length as a
function of the distance between the camera and the target. This follows from the fact that the effective resolution
decreases as an effect of perspective. This paper introduces
the Fourier tag, describes its design, and illustrates its properties experimentally.},
  keywords = {Robustness :  Distance ,Robustness :  Lightness}
}
@inproceedings{tateno2007nested,
  title={A nested marker for augmented reality},
  author={Tateno, Keisuke and Kitahara, Itaru and Ohta, Yuichi},
  booktitle={2007 IEEE Virtual Reality Conference},
  pages={259--262},
  year={2007},
  organization={IEEE},
  abstract = {A Nested Marker, a novel visual marker for camera calibration
in Augmented Reality (AR), enables accurate calibration even
when the observer is moving very close to or far away from the
marker. Our proposed Nested Marker has a recursive layered
structure. One marker at an upper layer contains four smaller
markers at the lower layer. Smaller markers can also have lowerlayer markers nesting inside them. Each marker can be identified
by its inside pattern, so the system can select a proper calibration
parameter set for the marker. When the observer views the marker
close-up, the lowest layer marker will work. When the observer
views the marker from a distance, the top-layer marker will work.
It is also possible to simultaneously utilize all visible markers in
different layers for more stable calibration. Note that Nested
Marker can be used in a standard ARToolkit framework. We have
also developed an AR system to demonstrate the ability of Nested
Marker.},
  keywords = { Robustness :  Motion Blur,Robustness :  Difficult angle , Robustness :  Distance ,Robustness :  Lightness,Robustness :  Noise,Robustness :  Radial distortion , Robustness :  Occlusion}
}
@inproceedings{schweiger2009maximum,
  title={Maximum Detector Response Markers for SIFT and SURF.},
  author={Schweiger, Florian and Zeisl, Bernhard and Georgel, Pierre Fite and Schroth, Georg and Steinbach, Eckehard G and Navab, Nassir},
  booktitle={VMV},
  volume={10},
  pages={145--154},
  year={2009},
  organization={Citeseer},
  abstract = {In this paper, we introduce optimal markers to be
used with the SIFT and SURF feature detectors.
They can be applied to trigger the detection of feature points at desired locations. Unlike conventional
marker systems, we do not propose a standalone solution comprising a set of markers and a thereto
adapted detection algorithm. Instead, our markers are adapted to existing and established detectors. In particular, we introduce markers optimally
suited for SIFT and SURF. We derive the optimal
design and show their high detectability within a
wide range of different imaging conditions in experiments on both synthetic and real data.},
  keywords = { Robustness :  Difficult angle ,
		 Robustness :  Distance , Robustness :  Noise }
}
@inproceedings{atcheson2010caltag,
  abstract = {We present a self-identifying marker pattern for camera calibration, together with the associated detection algorithm. The pattern is designed to support high-precision, fully-automatic localization of calibration points, as well
as identification of individual markers in the presence of significant occlusions, uneven illumination, and observations under extremely acute angles. The detection algorithm is efficient and free of parameters. After calibration
we obtain reprojection errors significantly lower than with state-of-the art self-identifying reference patterns.},
  keywords = {Robustness:Difficult angle,Robustness:Lightness,Robustness:Occlusion,Robustness:Radial distortion},
  title={Caltag: High precision fiducial markers for camera calibration.},
  author={Atcheson, Bradley and Heide, Felix and Heidrich, Wolfgang},
  booktitle={VMV},
  volume={10},
  pages={41--48},
  year={2010}
}
@inproceedings{kim2010fiducial,
  title={Fiducial marker indoor localization with artificial neural network},
  author={Kim, Gukhwan and Petriu, Emil M},
  booktitle={2010 IEEE/ASME International Conference on Advanced Intelligent Mechatronics},
  pages={961--966},
  year={2010},
  organization={IEEE},
  abstract = {A vision based positioning system could be
categorized into two groups. One analyzes an environment’s
scenery by matching the inputs with imaginary database to find
the optimum result. The other uses fiduciary markers. In
proposed method, the system uses fiduciary markers with a
capital alphabet in it. When the known size fiduciary marker is
captured by a camera, by using homography transformation, the
6-DOF camera pose with respect to the marker’s local
coordinate can be calculated. To recognize the character in the
marker, Artificial Neural Network (ANN) with backpropagation training method is used. 12 unique features of a
character are defined and used as inputs of ANN. Since more
than 95% recognition rate is achieved in testing phase, the
Optical Character Recognition (OCR) with ANN could be used
as a marker detection method. The localization experimental
result with the fiduciary marker shows that the proposed
method could be a solution for indoor localization.},
  keywords = {Robustness :  Radial distortion ,Robustness :  Distance}
}
@inproceedings{olson2011apriltag,
  title={AprilTag: A robust and flexible visual fiducial system},
  author={Olson, Edwin},
  booktitle={2011 IEEE international conference on robotics and automation},
  pages={3400--3407},
  year={2011},
  organization={IEEE},
  abstract = {While the use of naturally-occurring features is a
central focus of machine perception, artificial features (fiducials)
play an important role in creating controllable experiments,
ground truthing, and in simplifying the development of systems
where perception is not the central objective.
We describe a new visual fiducial system that uses a 2D bar
code style “tag”, allowing full 6 DOF localization of features
from a single image. Our system improves upon previous
systems, incorporating a fast and robust line detection system,
a stronger digital coding system, and greater robustness to
occlusion, warping, and lens distortion. While similar in concept
to the ARTag system, our method is fully open and the
algorithms are documented in detail.},
  keywords = {Robustness :  Computation Time ,Robustness :  Deformation , Robustness :  Difficult angle ,
		 Robustness :  Distance ,Robustness :  Lightness ,Robustness :  Occlusion ,Robustness :  Radial distortion}
}

@inproceedings{wang2016apriltag,
  title={AprilTag 2: Efficient and robust fiducial detection},
  author={Wang, John and Olson, Edwin},
  booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4193--4198},
  year={2016},
  organization={IEEE},
  abstract = {AprilTags and other passive fiducial markers require specialized algorithms to detect markers among other
features in a natural scene. The vision processing steps generally
dominate the computation time of a tag detection pipeline, so
even small improvements in marker detection can translate to
a faster tag detection system. We incorporated lessons learned
from implementing and supporting the AprilTag system into
this improved system.
This work describes AprilTag 2, a completely redesigned
tag detector that improves robustness and efficiency compared
to the original AprilTag system. The tag coding scheme is
unchanged, retaining the same robustness to false positives
inherent to the coding system. The new detector improves
performance with higher detection rates, fewer false positives,
and lower computational time. Improved performance on small
images allows the use of decimated input images, resulting in
dramatic gains in detection speed.},
  keywords = {Robustness :  Computation Time ,Robustness :  Difficult angle , Robustness :  Distance ,Robustness :  Lightness ,Robustness :  Occlusion

}
}
@inproceedings{bergamasco2011rune,
  title={Rune-tag: A high accuracy fiducial marker with strong occlusion resilience},
  author={Bergamasco, Filippo and Albarelli, Andrea and Rodola, Emanuele and Torsello, Andrea},
  booktitle={CVPR 2011},
  pages={113--120},
  year={2011},
  organization={IEEE},
  abstract = {Over the last decades fiducial markers have provided
widely adopted tools to add reliable model-based features
into an otherwise general scene. Given their central role
in many computer vision tasks, countless different solutions
have been proposed in the literature. Some designs are focused on the accuracy of the recovered camera pose with
respect to the tag; some other concentrate on reaching high
detection speed or on recognizing a large number of distinct
markers in the scene. In such a crowded area both the researcher and the practitioner are licensed to wonder if there
is any need to introduce yet another approach. Nevertheless, with this paper, we would like to present a general purpose fiducial marker system that can be deemed to add some
valuable features to the pack. Specifically, by exploiting
the projective properties of a circular set of sizeable dots,
we propose a detection algorithm that is highly accurate.
Further, applying a dot pattern scheme derived from errorcorrecting codes, allows for robustness with respect to very
large occlusions. In addition, the design of the marker itself
is flexible enough to accommodate different requirements in
terms of pose accuracy and number of patterns. The overall
performance of the marker system is evaluated in an extensive experimental section, where a comparison with a wellknown baseline technique is presented.},
  keywords = {Robustness :  Out-of-focus Blur ,Robustness :  Lightness ,
		 Robustness :  Difficult angle,Robustness :  Noise ,Robustness :  Occlusion }
}
@inproceedings{reuter2012blurtags,
  title={BlurTags: spatially varying PSF estimation with out-of-focus patterns},
  author={Reuter, Alexander and Seidel, Hans-Peter and Ihrke, Ivo},
  booktitle={20th International Conference on Computer Graphics, Visualization and Computer Vision 2012, WSCG'2012},
  pages={239--247},
  year={2012},
  abstract = {Current research is targeting the estimation and correction of lens imperfections. often modeled as a set of spatially
varying point spread functions (PSFs). One way to measure these PSFs is their calibration with checkerboard
patterns. Previous work, however, does not fully exploit all benefits of using a checkerboard. In particular, we show
in this paper that the pose of the checkerboard with respect to the camera can be exploited to yield information
on the circle of confusion, and thus the image blur of an ideal camera. By removing this expected blur, we can
estimate residual PSFs that are due to the deviation of the optical system from a thin-lens model. The residual
PSFs can then be used to sharpen images at comparable lens settings.
Practical side effects of our method are the design of a self-identifying pattern that can be robustly detected even
in the case of image blur, and a corresponding algorithm for its detection.},
  keywords = { Robustness :  Out-of-focus Blur ,
		 Robustness :  Lightness }
}
@inproceedings{li2012novel,
  title={A novel marker system in augmented reality},
  author={Li, Yun and Chen, Yimin and Lu, Renmiao and Ma, Deyi and Li, Qiming},
  booktitle={Proceedings of 2012 2nd International Conference on Computer Science and Network Technology},
  pages={1413--1417},
  year={2012},
  organization={IEEE},
  abstract = {In augmented reality systems, the three dimensional
registration technology based on artificial markers has been
widely used. The registration algorithm based on artificial
markers is divided into two steps: (1) marker detection and
recognition, (2) estimation of camera pose. In this paper, a
novel marker is designed based on projective invariants
principle, such as collinearity between points and cross-ratio.
Compared with the markers used in the ARToolkit, our new
marker can greatly reduce the storage space of marker
templates. And based on this marker, a new detection and
recognition algorithm is proposed. By using the algorithm, the
registration in AR system still can be successfully completed
even when the marker is occluded by 62.5%, which greatly
improves the robustness of the registration algorithm. The
experimental results show that the marker and the algorithm
posed in this paper are effective.},
  keywords = {Robustness :  Out-of-focus Blur ,Robustness :  Noise ,Robustness :  Occlusion}
}
@article{bergamasco2013pi,
  title={Pi-tag: a fast image-space marker design based on projective invariants},
  author={Bergamasco, Filippo and Albarelli, Andrea and Torsello, Andrea},
  journal={Machine vision and applications},
  volume={24},
  number={6},
  pages={1295--1310},
  year={2013},
  publisher={Springer},
  abstract = {Visual marker systems have become an
ubiquitous tool to supply a reference frame onto otherwise
uncontrolled scenes. Throughout the last decades, a wide
range of different approaches have emerged, each with different strengths and limitations. Some tags are optimized to
reach a high accuracy in the recovered camera pose, others
are based on designs that aim to maximizing the detection
speed or minimizing the effect of occlusion on the detection process. Most of them, however, employ a two-step procedure where an initial homography estimation is used to
translate the marker from the image plane to an orthonormal
world, where it is validated and recognized. In this paper,
we present a general purpose fiducial marker system that
performs both steps directly in image-space. Specifically,
by exploiting projective invariants such as collinearity and
cross-ratios, we introduce a detection and recognition algorithm that is fast, accurate and moderately robust to occlusion. The overall performance of the system is evaluated in
an extensive experimental section, where a comparison with
a well-known baseline technique is presented. Additionally,
several real-world applications are proposed, ranging from
camera calibration to projector-based augmented reality.},
  keywords = {Robustness :  Out-of-focus Blur ,Robustness :  Computation Time,Robustness :  Lightness ,
		 Robustness :  Difficult angle ,Robustness :  Noise ,Robustness :  Occlusion,  Robustness :  Radial distortion }
}
@inproceedings{liu2013real,
  title={Real time tracking method by using color markers},
  author={Liu, Jiamin and Chen, Shuo and Sun, Hongxing and Qin, Yongxu and Wang, Xibo},
  booktitle={2013 International Conference on Virtual Reality and Visualization},
  pages={106--111},
  year={2013},
  organization={IEEE},
  abstract = {To meet the user demands and to enhance
integrating of markers into the environment that is close to
nature as much as possible, this paper proposes a color
marker-based method for tracking the target object in real
time and registering a virtual three-dimensional (3D) object.
Firstly, the contours of the color marker patterns on the video
images are extracted by using adaptive threshold. Each
marker pattern on the image is corrected and recognized by
the template pattern. Secondly, the specified color markers are
identified by using the L1L2L3 and rgb models. Finally, the
virtual objects are registered in real-time on the marker image
by using the camera parameters derived from data of the color
markers. The experimental results show that the virtual
objects can be accurately registered on the markers of the
video images. Compared to the ARToolKit software, this
method is able to work in the environment with various
illumination conditions.},
  keywords = {Robustness :  Lightness }
}
@inproceedings{toyoura2013detecting,
  title={Detecting markers in blurred and defocused images},
  author={Toyoura, Masahiro and Aruga, Haruhito and Turk, Matthew and Mao, Xiaoyang},
  booktitle={2013 International Conference on Cyberworlds},
  pages={183--190},
  year={2013},
  organization={IEEE},
  abstract = {Planar markers enable an augmented reality (AR)
system to estimate the pose of objects from images containing
them. However, conventional markers are difficult to detect
in blurred or defocused images. We propose a new marker
and a new detection and identification method that is designed
to work under such conditions. The problem of conventional
markers is that their patterns consist of high-frequency components such as sharp edges which are attenuated in blurred
or defocused images. Our marker consists of a single lowfrequency component. We call it a mono-spectrum marker.
The mono-spectrum marker can be detected in real time with
a GPU. In experiments, we confirm that the mono-spectrum
marker can be accurately detected in blurred and defocused
images in real time. Using these markers can increase the
performance and robustness of AR systems and other vision
applications that require detection or tracking of defined
markers.},
  keywords = {Robustness :  Out-of-focus Blur}
}
@article{garrido2014automatic,
  title={Automatic generation and detection of highly reliable fiducial markers under occlusion},
  author={Garrido-Jurado, Sergio and Mu{\~n}oz-Salinas, Rafael and Madrid-Cuevas, Francisco Jos{\'e} and Mar{\'\i}n-Jim{\'e}nez, Manuel Jes{\'u}s},
  journal={Pattern Recognition},
  volume={47},
  number={6},
  pages={2280--2292},
  year={2014},
  publisher={Elsevier},
  abstract = {This paper presents a fiducial marker system specially appropriated for camera pose estimation in
applications such as augmented reality and robot localization. Three main contributions are presented.
First, we propose an algorithm for generating configurable marker dictionaries (in size and number of
bits) following a criterion to maximize the inter-marker distance and the number of bit transitions. In the
process, we derive the maximum theoretical inter-marker distance that dictionaries of square binary
markers can have. Second, a method for automatically detecting the markers and correcting possible
errors is proposed. Third, a solution to the occlusion problem in augmented reality applications is shown.
To that aim, multiple markers are combined with an occlusion mask calculated by color segmentation.
The experiments conducted show that our proposal obtains dictionaries with higher inter-marker
distances and lower false negative rates than state-of-the-art systems, and provides an effective solution
to the occlusion problem.},
  keywords = {Robustness :  Distance, Robustness :  Lightness ,Robustness :  Noise,Robustness :  Occlusion}
}
@inproceedings{klokmose2014bullseye,
  title={BullsEye: High-precision fiducial tracking for table-based tangible interaction},
  author={Klokmose, Clemens Nylandsted and Kristensen, Janus Bager and Bagge, Rolf and Halskov, Kim},
  booktitle={Proceedings of the Ninth ACM international conference on interactive tabletops and surfaces},
  pages={269--278},
  year={2014},
  abstract = {This paper proposes a series of techniques for improving the
precision of optical fiducial tracking on tangible tabletops.
The motivation is to enable convincing interactive projection
mapping on tangibles on the table, which requires a high precision tracking of the location of tangibles. We propose a new
fiducial design optimized for GPU based tracking, a technique for calibrating light that allows for computation on a
greyscale image rather than a binarized black and white image, an automated technique for compensating for optical distortions in the camera lenses, and a tracking algorithm implemented primarily in shaders on the GPU. The techniques
are realized in the BullsEye computer vision software. We
demonstrate experimentally that BullsEye provides sub-pixel
accuracy down to a tenth of a pixel, which is a significant
improvement compared to the commonly used reacTIVision
software.},
  keywords = {}
}
@inproceedings{prasad2015motion,
  title={A motion blur resilient fiducial for quadcopter imaging},
  author={Prasad, Meghshyam G and Chandran, Sharat and Brown, Michael S},
  booktitle={2015 IEEE Winter Conference on Applications of Computer Vision},
  pages={254--261},
  year={2015},
  organization={IEEE},
  abstract = {Fiducials are commonly placed in environments to provide a uniquely identifiable object in the scene. In quadcopter applications, these fiducials are often used to evaluate planning algorithms given that ground truth positions
can be detected from the quadcopter’s camera.
Low cost quadcopters, however, are subject to quick and
unstable motions that can cause significant motion blur that
severely affects the detection rate of existing fiducials. This
problem motivated us to design a fiducial that is robust to
motion blur. Our proposed design uses concentric circles
with the observation that the direction perpendicular to the
motion blur direction will be relatively unaffected by the
blur. As a result, an appropriate fiducial code orthogonal
to the blur direction can be recognized. Since the direction of motion blur is unknown, the circular design is good
for all motion blur directions. We describe the design of
binary fiducials, and also a detection algorithm. We show
that our marker can significantly outperform existing fiducials in scenes captured with a quadcopter.},
  keywords = {}
}
@inproceedings{calvet2016detection,
  title={Detection and accurate localization of circular fiducials under highly challenging conditions},
  author={Calvet, Lilian and Gurdjos, Pierre and Griwodz, Carsten and Gasparini, Simone},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={562--570},
  year={2016},
  abstract = {Using fiducial markers ensures reliable detection and
identification of planar features in images. Fiducials are
used in a wide range of applications, especially when a reliable visual reference is needed, e.g., to track the camera
in cluttered or textureless environments. A marker designed
for such applications must be robust to partial occlusions,
varying distances and angles of view, and fast camera motions. In this paper, we present a robust, highly accurate
fiducial system, whose markers consist of concentric rings,
along with its theoretical foundations. Relying on projective
properties, it allows to robustly localize the imaged marker
and to accurately detect the position of the image of the
(common) circle center. We demonstrate that our system
can detect and accurately localize these circular fiducials
under very challenging conditions and the experimental results reveal that it outperforms other recent fiducial systems.},
  keywords = {}
}


@online{Vumark,
    title        = {Vuforia Developer Library},
    author       = {Inc, PTC},
    year         = 2023,
    url          = {https://library.vuforia.com/objects/vumarks/},
    urldate      = {Accessed: 2023-09-30},
  abstract = {},
  keywords = {}
}
@inproceedings{degol2017chromatag,
  title={Chromatag: A colored marker and fast detection algorithm},
  author={DeGol, Joseph and Bretl, Timothy and Hoiem, Derek},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1472--1481},
  year={2017},
  abstract = {VuMarks are the next-generation bar code. They allows the freedom for a customized and brand-conscious design while simultaneously encoding data and acting as a trackable AR target. VuMark designs are completely customizable, so you can have a unique VuMark for every unique object.},
  keywords = {}
}
@article{lightbody2017efficient,
  title={An efficient visual fiducial localisation system},
  author={Lightbody, Peter and Krajn{\'\i}k, Tom{\'a}{\v{s}} and Hanheide, Marc},
  journal={ACM SIGAPP Applied Computing Review},
  volume={17},
  number={3},
  pages={28--37},
  year={2017},
  publisher={ACM New York, NY, USA},
  abstract = {With use cases that range from external localisation of single robots or robotic swarms to self-localisation in markeraugmented environments and simplifying perception by tagging objects in a robot’s surrounding, fiducial markers have
a wide field of application in the robotic world. We propose a
new family of circular markers which allow for both computationally efficient detection, tracking and identification and
full 6D position estimation. At the core of the proposed approach lies the separation of the detection and identification
steps, with the former using computationally efficient circular marker detection and the latter utilising an open-ended
‘necklace encoding’, allowing scalability to a large number of
individual markers. While the proposed algorithm achieves
similar accuracy to other state-of-the-art methods, its experimental evaluation in realistic conditions demonstrates
that it can detect markers from larger distances while being up to two orders of magnitude faster than other stateof-the art fiducial marker detection methods. In addition,
the entire system is available as an open-source package at
https://github.com/LCAS/whycon.},
  keywords = {}
}
@article{wang2018hierarchical,
  title={Hierarchical fiducial marker design for pose estimation in large-scale scenarios},
  author={Wang, Hao and Shi, Zongying and Lu, Geng and Zhong, Yisheng},
  journal={Journal of Field Robotics},
  volume={35},
  number={6},
  pages={835--849},
  year={2018},
  publisher={Wiley Online Library},
  abstract = {In this paper, a hierarchical fiducial marker, called HArCo, is designed to guarantee a smooth pose
estimation for large-scale applications. HArCo markers have a visually identifiable structure on
multiple scales, so they can be used for consistent pose estimation across a range of altitudes.
Experimental results are presented to validate the performance of the proposed methodologies;
oscillating platform landing experiments were conducted to show the ability of HArCo to be used
in real landing tasks on the deck of a ship.},
  keywords = {}
}
@article{benligiray2019stag,
  title={STag: A stable fiducial marker system},
  author={Benligiray, Burak and Topal, Cihan and Akinlar, Cuneyt},
  journal={Image and Vision Computing},
  volume={89},
  pages={158--169},
  year={2019},
  publisher={Elsevier},
  abstract = {Fiducial markers provide better-defined features than the ones naturally available in the scene. For this reason, they are widely utilized in computer vision
applications where reliable pose estimation is required. Factors such as imaging
noise and subtle changes in illumination induce jitter on the estimated pose. Jitter impairs robustness in vision and robotics applications, and deteriorates the
sense of presence and immersion in AR/VR applications. In this paper, we propose STag, a fiducial marker system that provides stable pose estimation. STag
is designed to be robust against jitter factors, thus sustains pose stability better than the existing solutions. This is achieved by utilizing geometric features
that can be localized more repeatably. The outer square border of the marker
is used for detection and homography estimation. This is followed by a novel
homography refinement step using the inner circular border. After refinement,
the pose can be estimated stably and robustly across viewing conditions. These
features are demonstrated with a comprehensive set of experiments, including
comparisons with the state of the art fiducial marker systems.},
  keywords = {}
}
@inproceedings{krogius2019flexible,
  title={Flexible layouts for fiducial tags},
  author={Krogius, Maximilian and Haggenmiller, Acshi and Olson, Edwin},
  booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={1898--1903},
  year={2019},
  organization={IEEE},
  abstract = {Fiducials are artificial features with a variety of
uses in computer vision such as object tracking and localization.
We propose the idea of flexible tag layouts for visual fiducial
systems. In contrast to traditional square tags, flexible tag
layouts allow circular, annular, or other shapes as desired.
One use of layout flexibility is to increase the data density of
standard square shaped tags. In addition, we describe a detector
that is faster and has higher recall than both the AprilTag 2
and ArUco detectors while maintaining precision.},
  keywords = {}
}
@article{yu2020topotag,
  title={Topotag: A robust and scalable topological fiducial marker system},
  author={Yu, Guoxing and Hu, Yongtao and Dai, Jingwen},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  volume={27},
  number={9},
  pages={3769--3780},
  year={2020},
  publisher={IEEE},
  abstract = {Fiducial markers have been playing an important role in augmented reality (AR), robot navigation, and general applications
where the relative pose between a camera and an object is required. Here we introduce TopoTag, a robust and scalable topological
fiducial marker system, which supports reliable and accurate pose estimation from a single image. TopoTag uses topological and
geometrical information in marker detection to achieve higher robustness. Topological information is extensively used for 2D marker
detection, and further corresponding geometrical information for ID decoding. Robust 3D pose estimation is achieved by taking
advantage of all TopoTag vertices. Without sacrificing bits for higher recall and precision like previous systems, TopoTag can use full
bits for ID encoding. TopoTag supports tens of thousands unique IDs and easily extends to millions of unique tags resulting in massive
scalability. We collected a large test dataset including in total 169,713 images for evaluation, involving in-plane and out-of-plane
rotation, image blur, different distances, and various backgrounds, etc. Experiments on the dataset and real indoor and outdoor scene
tests with a rolling shutter camera both show that TopoTag significantly outperforms previous fiducial marker systems in terms of
various metrics, including detection accuracy, vertex jitter, pose jitter and accuracy, etc. In addition, TopoTag supports occlusion as
long as the main tag topological structure is maintained and allows for flexible shape design where users can customize internal and
external marker shapes. Code for our marker design/generation, marker detection, and dataset are available at http://herohuyongtao.
github.io/research/publications/topo-tag/.},
  keywords = {}
}
@inproceedings{wang2020lftag,
  title={LFTag: A scalable visual fiducial system with low spatial frequency},
  author={Wang, Ben},
  booktitle={2020 2nd International Conference on Advances in Computer Technology, Information Science and Communications (CTISC)},
  pages={140--147},
  year={2020},
  organization={IEEE},
  abstract = {Visual fiducial systems are a key component of
many robotics and AR/VR applications for 6-DOF monocular
relative pose estimation and target identification. This paper
presents LFTag, a visual fiducial system based on topological
detection and relative position data encoding which optimizes
data density within spatial frequency constraints. The marker
is constructed to resolve rotational ambiguity, which combined
with the robust geometric and topological false positive rejection,
allows all marker bits to be used for data.
When compared to existing state-of-the-art square binary
markers (AprilTag) and topological markers (TopoTag) in simulation, the proposed fiducial system (LFTag) offers significant
advances in dictionary size and range. LFTag 3x3 achieves 546
times the dictionary size of AprilTag 25h9 and LFTag 4x4
achieves 126 thousand times the dictionary size of AprilTag 41h12
while simultaneously achieving longer detection range. LFTag 3x3
also achieves more than twice the detection range of TopoTag 4x4
at the same dictionary size.},
  keywords = {}
}
@article{kovstak2021designing,
  title={Designing a Simple Fiducial Marker for Localization in Spatial Scenes Using Neural Networks},
  author={Ko{\v{s}}t'{\'a}k, Milan and Slab{\`y}, Anton{\'\i}n},
  journal={Sensors},
  volume={21},
  number={16},
  pages={5407},
  year={2021},
  publisher={MDPI},
  abstract = {The paper describes the process of designing a simple fiducial marker. The marker is meant
for use in augmented reality applications. Unlike other systems, it does not encode any information,
but it can be used for obtaining the position, rotation, relative size, and projective transformation.
Also, the system works well with motion blur and is resistant to the marker’s imperfections, which
could theoretically be drawn only by hand. Previous systems put constraints on colors that need to
be used to form the marker. The proposed system works with any saturated color, leading to better
blending with the surrounding environment. The marker’s final shape is a rectangular area of a
solid color with three lines of a different color going from the center to three corners of the rectangle.
Precise detection can be achieved using neural networks, given that the training set is very varied
and well designed. A detailed literature review was performed, and no such system was found.
Therefore, the proposed design is novel for localization in the spatial scene. The testing proved that
the system works well both indoor and outdoor, and the detections are precise.},
  keywords = {}
}
@article{zhang2022deeptag,
  title={DeepTag: A general framework for fiducial marker design and detection},
  author={Zhang, Zhuming and Hu, Yongtao and Yu, Guoxing and Dai, Jingwen},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2022},
  publisher={IEEE},
  abstract = {A fiducial marker system usually consists of markers, a detection algorithm, and a coding system. The appearance of
markers and the detection robustness are generally limited by the existing detection algorithms, which are hand-crafted with traditional
low-level image processing techniques. Furthermore, a sophisticatedly designed coding system is required to overcome the
shortcomings of both markers and detection algorithms. To improve the flexibility and robustness in various applications, we propose a
general deep learning based framework, DeepTag, for fiducial marker design and detection. DeepTag not only supports detection of a
wide variety of existing marker families, but also makes it possible to design new marker families with customized local patterns.
Moreover, we propose an effective procedure to synthesize training data on the fly without manual annotations. Thus, DeepTag can
easily adapt to existing and newly-designed marker families. To validate DeepTag and existing methods, beside existing datasets, we
further collect a new large and challenging dataset where markers are placed in different view distances and angles. Experiments
show that DeepTag well supports different marker families and greatly outperforms the existing methods in terms of both detection
robustness and pose accuracy. Both code and dataset are available at https://herohuyongtao.github.io/research/publications/deep-tag/.},
  keywords = {}
}
@article{jurado2021design,
  title={Design, Detection, and Tracking of Customized Fiducial Markers},
  author={Jurado-Rodr{\'\i}guez, David and Mu{\~n}oz-Salinas, Rafael and Garrido-Jurado, Sergio and Medina-Carnicer, Rafael},
  journal={IEEE Access},
  volume={9},
  pages={140066--140078},
  year={2021},
  publisher={IEEE},
  abstract = {Fiducial markers such as QR codes, ArUco, and AprilTag have become very popular tools for
labeling and camera positioning. They are robust and easy to detect, even in devices with low computing
power. However, their industrial appearance deters their use in scenarios where an attractive and visually
appealing look is required. In these cases, it would be preferable to use customized markers showing, for
instance, a company logo. This work proposes a novel method to design, detect, and track customizable
fiducial markers. Our work allows creating markers templates imposing few restrictions on its design, e.g.,
a company logo or a picture can be used. The designer must indicate positions into the template where bits
will encode a unique identifier for each marker. Then, our method will automatically create a dictionary
of markers, all following the same design, but each with a unique identifier. Finally, we propose a method
for detecting and tracking the markers even under occlusion, which is not allowed in traditional fiducial
markers. The experiments conducted show that the performance of the customizable markers is similar to
the best traditional markers systems without significantly sacrificing speed.},
  keywords = {}
}
@article{wu2021closed,
  title={Closed-loop pose control and automated suturing of continuum surgical manipulators with customized wrist markers under stereo vision},
  author={Wu, Baibo and Wang, Longfei and Liu, Xu and Wang, Linhui and Xu, Kai},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={4},
  pages={7137--7144},
  year={2021},
  publisher={IEEE},
  abstract = {The use of continuum manipulators in surgical applications can be beneficial because of their inherent safety from
their structural compliance. However, the tip pose (position and
orientation) accuracy of a continuum manipulator can be low
when an external load or disturbance is applied. Closed-loop pose
control is preferred to improve the pose accuracy. Considering
the requirements stemmed from sterilization and medical device
electromagnetic compatibility, the approach of fully utilizing the
vision feedback from a stereo endoscopic camera for such a closedloop pose controller is adopted. Wrist markers are attached to
the end-effectors of the surgical continuum manipulators for pose
information detection. And these wrist markers are designed in a
well-considered way to generate enough variants. The closed-loop
pose controller is then designed based on a stereo vision tracking
algorithm that detects the position and orientation of the wrist
marker. A switching feature is also incorporated into the controller
to handle the situation when the closed-loop control is disrupted
due to the visual occlusion or the operation transition in dual-arm
manipulation. Experimental verification showed that the average
errors of the pose feedback are 0.65 mm for the position and 1.05°
for the orientation. The experiments of trajectory following under
a 120-gram external load and automated dual-arm suturing were
also conducted to verify the effectiveness of the proposed controller.},
  keywords = {}
}




@inproceedings{tushev2018robust,
  title={Robust coded target recognition in adverse light conditions},
  author={Tushev, Semyon and Sukhovilov, Boris and Sartasov, Evgeniy},
  booktitle={2018 International Conference on Industrial Engineering, Applications and Manufacturing (ICIEAM)},
  pages={1--6},
  year={2018},
  organization={IEEE},
  abstract = {We propose a new algorithm for the robust
identification of coded targets in adverse light conditions. The
new algorithm relies on the recognition of circle retroreflective
targets. The algorithm finalizes the process of development of
multi-functional coded targets for high-precision
photogrammetric systems. The main advantages of the new
algorithm are tolerance to adverse light conditions and a high
speed. This paper reviews existing architectures of coded targets
and their identification methods. We propose and describe the
architecture of a coded target for high-precision
photogrammetric measurements. We also analyze the efficiency
of new algorithms and the range of their possible applications.},
  keywords = {}
}
@article{romero2019fractal,
  title={Fractal Markers: a new approach for long-range marker pose estimation under occlusion},
  author={Romero-Ramire, Francisco J and Munoz-Salinas, Rafael and Medina-Carnicer, Rafael},
  journal={IEEE Access},
  volume={7},
  pages={169908--169919},
  year={2019},
  publisher={IEEE},
  abstract = {Squared fiducial markers are a powerful tool for camera pose estimation in applications such as
robots, unmanned vehicles and augmented reality. The four corners of a single marker are enough to estimate
the pose of a calibrated camera. However, they have some limitations. First, the methods proposed for
detection are ineffective under occlusion. A small occlusion in any part of the marker makes it undetectable.
Second, the range at which they can be detected is limited by their size. Very big markers can be detected
from a far distance, but as the camera approaches them, they are not fully visible, and thus they can not be
detected. Small markers, however, can not be detected from large distances. This paper proposes solutions
to the above-mentioned problems. We propose the Fractal Marker, a novel type of marker that is built as an
aggregation of squared markers, one into another, in a recursive manner. Also, we proposed a novel method
for detecting Fractal Markers under severe occlusions. The results of our experiments show that the proposed
method achieves a wider detection range than traditional markers and great robustness to occlusion.},
  keywords = {}
}

@inproceedings{elbrechter2011bi,
  title={Bi-manual robotic paper manipulation based on real-time marker tracking and physical modelling},
  author={Elbrechter, Christof and Haschke, Robert and Ritter, Helge},
  booktitle={2011 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={1427--1432},
  year={2011},
  organization={IEEE},
  abstract = {The ability to manipulate deformable objects, such
as textiles or paper, is a major prerequisite to bringing the
capabilities of articulated robot hands closer to the level of
manual intelligence exhibited by humans. We concentrate on
the manipulation of paper, which affords us a rich interaction
domain and that has not yet been solved for anthropomorphic
robot hands. A key ability needed for this is the robust tracking
and modelling of paper under conditions of occlusion and
strong deformation. We present a marker based framework
that realizes these properties robustly and in real-time. We
compare a purely mathematical representation of the paper
manifold with a soft-body-physics model and demonstrate the
use of our visual tracking method to facilitate the coordination
of two anthropomorphic 20 DOF Shadow Dexterous Hands
while they grasp a flat-lying piece of paper, using a combination
of visually guided bulging and pinching.},
  keywords = {}
}


@inproceedings{mooser2006tricodes,
  title={Tricodes: A barcode-like fiducial design for augmented reality media},
  author={Mooser, Jonathan and You, Suya and Neumann, Ulrich},
  booktitle={2006 IEEE International Conference on Multimedia and Expo},
  pages={1301--1304},
  year={2006},
  organization={IEEE},
  abstract = {Visual markers, or fiducials, have become one of the most common
methods of camera pose estimation in Augmented Reality (AR) media. Many present day fiducial-based AR systems use arbitrary patterns, such as simple line drawings or alpha-numeric characters, and
require that an application be “trained” to recognize its pattern set.
These techniques work well on a small scale, but as the number of
fiducials grows, accuracy and performance degrade. We describe a
new fiducial design called TriCodes that, like a barcode, provides a
systematic way of printing and identifying a vast library of patterns.
We compare TriCodes to the popular ARToolkit package, demonstrating its advantages in the presence of large numbers of fiducials.},
  keywords = {}
}




@inproceedings{bondy2007space,
  title={Space vision marker system (SVMS)},
  author={Bondy, Michel and Krishnasamy, Rubakumar and Crymble, Derry and Jasiobedzki, Piotr},
  booktitle={AIAA SPACE 2007 Conference \& Exposition},
  pages={6185},
  year={2007},
  abstract = {Visual targets are used in space proximity operations to help in alignment of mechanical
interfaces during, for example, spacecraft rendezvous and docking, and in robotic servicing
of space structures. Distinctive and precisely placed target features facilitate unambiguous
and reliable detection, and accurate estimation of relative position and orientation (pose) by
the human operators or automatic vision systems. Existing targets used by vision systems
typically do not allow for identification or for multiple targets to be visible in the field of
view. The targets are detected in the first image and are tracked in successive frames, which
introduce a potential failure condition. This paper describes a novel concept of a Space
Vision Marker System (SVMS). Inspired by past designs of space targets and terrestrial
marker systems, SVMS combines positive features of both and extends them to space
applications. SVMS includes: the design of a family of markers, preferred imaging
arrangement (camera, light, marker material), and software algorithms to detect the
markers. The markers are reliably detected under a wide range of viewing distances and
angles, and illumination (including direct sun light and shadows); encoded redundant
features allow identification even with a partial data loss. Three dimensional structures of
the markers allow accurate pose estimation. The detection algorithms operate on each image
separately and in real time, which does not require tracking between frames and allows
instant recovery from failures due to, e.g., marker occlusions. Results of laboratory tests
performed under conditions representative to proximity operations in lower earth orbit are
also presented.},
  keywords = {}
}


@inproceedings{birdal2016x,
  title={X-tag: A fiducial tag for flexible and accurate bundle adjustment},
  author={Birdal, Tolga and Dobryden, Ievgeniia and Ilic, Slobodan},
  booktitle={2016 Fourth International Conference on 3D Vision (3DV)},
  pages={556--564},
  year={2016},
  organization={IEEE},
  abstract = {In this paper we design a novel planar 2D fiducial
marker and develop fast detection algorithm aiming easy
camera calibration and precise 3D reconstruction at the
marker locations via the bundle adjustment. Even though
an abundance of planar fiducial markers have been made
and used in various tasks, none of them has properties necessary to solve the aforementioned tasks. Our marker, Xtag, enjoys a novel design, coupled with very efficient and
robust detection scheme, resulting in a reduced number of
false positives. This is achieved by constructing markers
with random circular features in the image domain and encoding them using two true perspective invariants: crossratios and intersection preservation constraints. To detect
the markers, we developed an effective search scheme, similar to Geometric Hashing and Hough Voting, in which the
marker decoding is cast as a retrieval problem. We apply
our system to the task of camera calibration and bundle adjustment. With qualitative and quantitative experiments, we
demonstrate the robustness and accuracy of X-tag in spite
of blur, noise, perspective and radial distortions, and showcase camera calibration, bundle adjustment and 3d fusion
of depth data from precise extrinsic camera poses.},
  keywords = {}
}
@article{cruz2018fiducial,
  title={A fiducial tag invariant to rotation, translation, and perspective transformations},
  author={Cruz-Hern{\'a}ndez, Heriberto and de la Fraga, Luis Gerardo},
  journal={Pattern Recognition},
  volume={81},
  pages={213--223},
  year={2018},
  publisher={Elsevier},
  abstract = {This work introduces a novel visual fiducial tag appropriate for applications of
automatic identification. The proposed tag is based in Order Type, a construction defined in Computational Geometry, which is invariant to 3D translation,
rotation, and projective transformations. Three main contributions are presented: first we describe the design of the proposed tags, the procedures for
detecting them from an image, and the algorithms for computing an identifier
from them. Second, we analyze the feasibility of the proposal in three different
conditions of tag’s rotation, distance to the tag, and the effect of noise in point
positions for the recognition process. Third, we show the applicability of the
proposed tags with simulated images. The conducted experiments indicate that
the tags are very robust to the image generation process, suitable for automatic
identification up to 3 472 different tags, and also for the pose estimation in
Computer Vision applications.},
  keywords = {}
}
@article{li2007fiducial,
  title={Fiducial marker based on projective invariant for augmented reality},
  author={Li, Yu and Wang, Yong-Tian and Liu, Yue},
  journal={Journal of Computer Science and Technology},
  volume={22},
  number={6},
  pages={890--897},
  year={2007},
  publisher={Springer US Boston},
  abstract = {Fiducial marker based Augmented Reality has many applications. So far the inner pattern of the fiducial marker is always used to encode the markers. Thus a large portion of the fiducial marker image is used for encoding instead of providing corresponding feature points for pose accuracy. This paper presents a novel method which utilizes directly the projective invariant contained in the positional relation of the corresponding feature point's to encode the marker. The proposed method does not require the region of pattern image for encoding any more and can provide more corresponding feature points so that higher pose accuracy can be achieved easily. Many related approaches such as cumulative distribution function, reprojection verification and robust process are proposed to overcome the problem of sensibility of the projective invariant. Experimental results show that the proposed fiducial marker system is reliable and robust, and can provide higher pose accuracy than that achieved by existing fiducial marker systems.
},
  keywords = {}
}



@inproceedings{nguyen2016stereotag,
  title={StereoTag: A novel stereogram-marker-based approach for Augmented Reality},
  author={Nguyen, Minh and Yeap, Albert},
  booktitle={2016 23rd International Conference on Pattern Recognition (ICPR)},
  pages={1059--1064},
  year={2016},
  organization={IEEE},
  abstract = {Augmented Reality (AR) is an active and exciting
topic aiming to create intuitive computer interface by blending
reality and virtual reality. One challenge of AR is to align virtual
data with the environment. Typically, one uses a marker-based
approach such as a thick-bordered black and white 2D marker
which allows one to recover the relative pose (location and
orientation) of a camera in real time. However, bar-code markers
do not contain any intuitive visual meaning, and they thus look
uninteresting and uninformative. We propose a new type of
marker, referred to as a StereoTag, which embeds a meaningful
stereogram image hiding 3D coded/decoded information. From
experiments conducted, our StereoTag is found to be relatively
robust under various conditions and thus could be widely used
in future AR applications.},
  keywords = {}
}

@article{nishino2010topolo,
  title={Topolo surface: A 2d fiducial tracking system based on topological region adjacency and angle information},
  author={Nishino, Hiroki},
  journal={Information and Media Technologies},
  volume={5},
  number={2},
  pages={479--488},
  year={2010},
  publisher={Information and Media Technologies Editorial Board},
  abstract = {Augmented Reality (AR) is an active and exciting
topic aiming to create intuitive computer interface by blending
reality and virtual reality. One challenge of AR is to align virtual
data with the environment. Typically, one uses a marker-based
approach such as a thick-bordered black and white 2D marker
which allows one to recover the relative pose (location and
orientation) of a camera in real time. However, bar-code markers
do not contain any intuitive visual meaning, and they thus look
uninteresting and uninformative. We propose a new type of
marker, referred to as a StereoTag, which embeds a meaningful
stereogram image hiding 3D coded/decoded information. From
experiments conducted, our StereoTag is found to be relatively
robust under various conditions and thus could be widely used
in future AR applications.},
  keywords = {}
}
@inproceedings{rice2006cantag,
  title={Cantag: an open source software toolkit for designing and deploying marker-based vision systems},
  author={Rice, Andrew C and Beresford, Alastair R and Harle, Robert K},
  booktitle={Fourth Annual IEEE International Conference on Pervasive Computing and Communications (PERCOM'06)},
  pages={10--pp},
  year={2006},
  organization={IEEE},
  abstract = {This paper presents Cantag, an open source software
toolkit for building Marker-based Vision (MBV) systems
that can identify and accurately locate printed markers in
three dimensions. The extensibility of the system makes it
ideal for dynamic location and pose determination in pervasive computing systems. Unlike prior MBV systems, Cantag
supports multiple fiducial shapes, payload types, data sizes
and image processing algorithms in one framework. It allows the application writer to generate a custom tag design
and associated optimised executable for any given application. The system includes a test harness which can be used
to quantify, compare and contrast the performance of different designs. This paper explores the design space of tags
within the Cantag system, and describes the design parameters and performance characteristics which an application
writer can use to select the best tag system for any given scenario. It presents quantitative analysis of different markers
and processing algorithms, which are compared fairly for
the first time.},
  keywords = {}
}
@incollection{higashino2016arttag,
  title={ARTTag: aesthetic fiducial markers based on circle pairs},
  author={Higashino, Shinichi and Nishi, Sakiko and Sakamoto, Ryuuki},
  booktitle={ACM SIGGRAPH 2016 Posters},
  pages={1--2},
  year={2016},
  abstract = {In this paper, we present ARTTag, an aesthetic fiducial marker
system, of which the design development can be performed with
any color, texture, shape, or other features as long as circle pairs
are integrated. By utilizing the projective properties of circular
features, ARTTag is appropriate for detection, identification, and
camera-based registration in augmented reality (AR) applications.},
  keywords = {}
}
@inproceedings{nishino2010shape,
  title={A shape-free, designable 6-DoF marker tracking method for camera-based interaction in mobile environment},
  author={Nishino, Hiroki},
  booktitle={Proceedings of the 18th ACM international conference on Multimedia},
  pages={1055--1058},
  year={2010},
  abstract = {We developed a novel marker tracking method with shape-free,
designable markers, which can be visually meaningful to users.
The method can work fast enough to provide a real-time camerabased interaction even on low performance CPUs such as ones
used in mobile Internet devices. Features such as visually
communicative design and inexpensive computational cost are
very desirable for users with mobile devices in the
mobile/pervasive interaction environment.
The method utilizes the topological region adjacency to detect the
marker candidates and then apply a simple method similar to
geometric-hashing to determine the detected maker by voting to
the hash tables. By such a combination of two different
approaches, our method can distinguish those markers with the
same topological structure and is also capable of 6-DoF pose
estimation whereas most of the existing topology-based systems
can not distinguish markers with the same topological structure
and are incapable of 6-DoF pose estimation.},
  keywords = {}
}
@inproceedings{farkas2012aesthetic,
  title={Aesthetic marker design for home robot localization},
  author={Farkas, Zita V and Korondi, P{\'e}ter and Illy, D{\'a}niel and Fodor, L{\'o}r{\'a}nt},
  booktitle={IECON 2012-38th Annual Conference on IEEE Industrial Electronics Society},
  pages={5510--5515},
  year={2012},
  organization={IEEE},
  abstract = {A new and aesthetic marker technique for
indoor robot localization is presented in this paper. The
marker, as a visual landmark, is designed to fit human
inhabited indoor environments, where aesthetic
considerations are as much important as efficiency of the
visual localization. Design development was performed
using color filtration and shape detection of the marker
image. HSV color space was used for color separation,
then hue component values of the highest geometric
distance were selected for contrast decisions. This method
allows the extraction of contrasting color information,
where contrast values were lowered until machine visual
detection was efficient enough whilst marker image
aesthetics were still enjoyable for the human viewer.
Separated colors were examined by shape detection for
geometry, size and orientation to introduce the marker
elements. Results of the aesthetic marker feature tracking
illustrate marker information retrieval. In conclusion,
aesthetic markers, when harmonized with color
preference, can be integrated unobtrusively into home
environments and are efficient for robot localization.},
  keywords = {}
}
@article{yaldiz2022deepformabletag,
  title={Deepformabletag: end-to-end generation and recognition of deformable fiducial markers},
  author={Yaldiz, Mustafa B and Meuleman, Andreas and Jang, Hyeonjoong and Ha, Hyunho and Kim, Min H},
  journal={arXiv preprint arXiv:2206.08026},
  year={2022},
  abstract = {Fiducial markers have been broadly used to identify objects or embed messages that can be detected by a camera. Primarily, existing detection methods
assume that markers are printed on ideally planar surfaces. The size of a
message or identification code is limited by the spatial resolution of binary
patterns in a marker. Markers often fail to be recognized due to various imaging artifacts of optical/perspective distortion and motion blur. To overcome
these limitations, we propose a novel deformable fiducial marker system that
consists of three main parts: First, a fiducial marker generator creates a set
of free-form color patterns to encode significantly large-scale information
in unique visual codes. Second, a differentiable image simulator creates a
training dataset of photorealistic scene images with the deformed markers,
being rendered during optimization in a differentiable manner. The rendered
images include realistic shading with specular reflection, optical distortion,
defocus and motion blur, color alteration, imaging noise, and shape deformation of markers. Lastly, a trained marker detector seeks the regions of
interest and recognizes multiple marker patterns simultaneously via inverse
deformation transformation. The deformable marker creator and detector
networks are jointly optimized via the differentiable photorealistic renderer
in an end-to-end manner, allowing us to robustly recognize a wide range
of deformable markers with high accuracy. Our deformable marker system
is capable of decoding 36-bit messages successfully at ∼29 fps with severe
shape deformation. Results validate that our system significantly outperforms the traditional and data-driven marker methods. Our learning-based
marker system opens up new interesting applications of fiducial markers, including cost-effective motion capture of the human body, active 3D scanning using our fiducial markers’ array as structured light patterns, and robust
augmented reality rendering of virtual objects on dynamic surfaces},
  keywords = {}
}

@inproceedings{nishino20106dof,
  title={A 6dof fiducial tracking method based on topological region adjacency and angle information for tangible interaction},
  author={Nishino, Hiroki},
  booktitle={Proceedings of the fourth international conference on Tangible, embedded, and embodied interaction},
  pages={253--256},
  year={2010},
  abstract = {In this paper, we describe a new method for camera-based
fiducial tracking. Our new method is based on the
combination of topological region adjacency and angle
information, where as related works by Johnston’s RAG
target [7], Costanza’s D-Touch [3], and Kaltenbrunner’s
reacTIVision [2] are based on the uniqueness of the
topological region adjacency structure.
Such a combination of the topological region adjacency and
angle information enables a wider unique ID range, while
maintaining the merit of fast and robust fiducial tracking in
topology-based approach. Our method makes it possible to
obtain the 6 degrees-of-freedom (6DoF). Such problems of
a narrow unique ID range and lack of 6DoF information
have been the main deficits in most systems based on
topological region adjacency approach, when compared to
other fiducial tracking methods.},
  keywords = {}
}
@inproceedings{getschmann2021seedmarkers,
  title={Seedmarkers: Embeddable Markers for Physical Objects},
  author={Getschmann, Christopher and Echtler, Florian},
  booktitle={Proceedings of the Fifteenth International Conference on Tangible, Embedded, and Embodied Interaction},
  pages={1--11},
  year={2021},
  abstract = {We present Seedmarkers, shape-independent topological markers
that can be embedded in physical objects manufactured with common rapid-prototyping techniques. Many markers are optimized for
technical performance while visual appearance or the feasibility of
permanently merging marker and physical object is not considered.
We give an overview of the aesthetic properties of a wide range
of existing markers and conducted a short online survey to assess
the perception of popular marker designs. Based on our findings
we introduce our generation algorithm making use of weighted
Voronoi diagrams for topological optimization. With our generator,
Seedmarkers can be created from technical drawings during the
design process to fill arbitrary shapes on any surface. Given dimensions and manufacturing constraints, different configurations for
3 or 6 degrees of freedom tracking are possible. We propose a set
of application examples for shape-independent markers, including
3D printed tangibles, laser cut plates and functional markers on
printed circuit boards.},
  keywords = {}
}
@article{peace2021e2etag,
  title={E2etag: An end-to-end trainable method for generating and detecting fiducial markers},
  author={Peace, J Brennan and Psota, Eric and Liu, Yanfeng and P{\'e}rez, Lance C},
  journal={arXiv preprint arXiv:2105.14184},
  year={2021},
  abstract = {Existing fiducial markers solutions are designed for efficient detection and decoding, however, their ability to stand out in natural environments is difficult to infer from
relatively limited analysis. Furthermore, worsening performance in challenging image
capture scenarios - such as poor exposure, motion blur, and off-axis viewing - sheds
light on their limitations. E2ETag introduces an end-to-end trainable method for designing fiducial markers and a complimentary detector. By introducing back-propagatable
marker augmentation and superimposition into training, the method learns to generate
markers that can be detected and classified in challenging real-world environments using
a fully convolutional detector network. Results demonstrate that E2ETag outperforms
existing methods in ideal conditions and performs much better in the presence of motion
blur, contrast fluctuations, noise, and off-axis viewing angles. Source code and trained
models are available at https://github.com/jbpeace/E2ETag.},
  keywords = {}
}
@inproceedings{scheirer2022dynatags,
  title={DynaTags: Low-Cost Fiducial Marker Mechanisms},
  author={Scheirer, Cassandra and Harrison, Chris},
  booktitle={Proceedings of the 2022 International Conference on Multimodal Interaction},
  pages={432--443},
  year={2022},
  abstract = {Printed fducial markers are inexpensive, easy to deploy, robust
and deservedly popular. However, their data payload is also static,
unable to express any state beyond being present. For this reason,
more complex electronic tagging technologies exist, which can
sense and change state, but either require special equipment to read
or are orders of magnitude more expensive than printed markers.
In this work, we explore an approach between these two extremes:
one that retains the simple, low-cost nature of printed markers,
yet has some of the expressive capabilities of dynamic tags. Our
“DynaTags” are simple mechanisms constructed from paper that
express multiple payloads, allowing practitioners and researchers
to create new and compelling physical-digital experiences. We
describe a library of 23 mechanisms that can be read by standard
smartphone reader apps. Through a series of demo applications
(augmenting reality through e.g., sounds, environmental lighting
and graphics) we show how our tags can bring new interactivity to
previously static experiences.},
  keywords = {}
}
@inproceedings{yang2014robust,
  title={Robust random dot markers: towards augmented unprepared maps with pure geographic features},
  author={Yang, Liming and Normand, Jean-Marie and Moreau, Guillaume},
  booktitle={Proceedings of the 20th ACM Symposium on Virtual Reality Software and Technology},
  pages={45--54},
  year={2014},
  abstract = {Augmented maps have many important applications. However, no mature registration method exists to associate unprepared maps with a Geographical Information System (GIS) database which would be used to superimpose simulation results or route display on a paper map. In this paper, we propose a method called Robust Ran- dom Dot Markers (RRDM) that can robustly track coplanar random dot patterns, which can be used to address this problem. RRDM is based on the same idea of the Random Dot Markers (RDM) pro- posed by [Uchiyama and Saito 2011] and it can serve as fiducial markers as well as texture independent "natural markers". We con- duct a series of experiments and show that RRDM is more robust than RDM in terms of jitter, perspective distortion, under and over detection of dots in the pattern. As an example of "natural marker", we show that RRDM can successfully register unprepared printed maps only with pure geographic features, i.e. road intersections coordinates, which we retrieve from a GIS. Our method does not suffer from the drawbacks of traditional "feature-point" based reg- istration methods which mainly based on textures, since textures may change according to different maps.},
  keywords = {}
}
@article{mateos2020apriltags,
  title={Apriltags 3d: dynamic fiducial markers for robust pose estimation in highly reflective environments and indirect communication in swarm robotics},
  author={Mateos, Luis A},
  journal={arXiv preprint arXiv:2001.08622},
  year={2020},
  abstract = {Although fiducial markers give an accurate pose estimation in laboratory conditions, where the noisy factors are
controlled, using them in field robotic applications remains
a challenge. This is constrained to the fiducial maker systems, since they only work within the RGB image space.
As a result, noises in the image produce large pose estimation errors. In robotic applications, fiducial markers have
been mainly used in its original and simple form, as a plane
in a printed paper sheet. This setup is sufficient for basic visual servoing and augmented reality applications, but
not for complex swarm robotic applications in which the
setup consists of multiple dynamic markers (tags displayed
on LCD screen).
This paper describes a novel methodology, called AprilTags3D, that improves pose estimation accuracy of AprilTags
in field robotics with only RGB sensor by adding a third dimension to the marker detector. Also, presents experimental
results from applying the proposed methodology to swarm
autonomous robotic boats for latching between them and
for creating robotic formations.},
  keywords = {}
}
@article{romero2018speeded,
  title={Speeded up detection of squared fiducial markers},
  author={Romero-Ramirez, Francisco J and Mu{\~n}oz-Salinas, Rafael and Medina-Carnicer, Rafael},
  journal={Image and vision Computing},
  volume={76},
  pages={38--47},
  year={2018},
  publisher={Elsevier},
  abstract = {Squared planar markers have become a popular method for pose estimation in applications such as autonomous robots,
unmanned vehicles or virtual trainers. The markers allow estimating the position of a monocular camera with minimal
cost, high robustness, and speed. One only needs to create markers with a regular printer, place them in the desired
environment so as to cover the working area, and then registering their location from a set of images.
Nevertheless, marker detection is a time-consuming process, especially as the image dimensions grows. Modern cameras
are able to acquire high resolutions images, but fiducial marker systems are not adapted in terms of computing speed.
This paper proposes a multi-scale strategy for speeding up marker detection in video sequences by wisely selecting the
most appropriate scale for detection, identification and corner estimation. The experiments conducted show that the
proposed approach outperforms the state-of-the-art methods without sacrificing accuracy or robustness. Our method is
up to 40 times faster than the state-of-the-art method, achieving over 1000 fps in 4K images without any parallelization.},
  keywords = {}
}

@article{zhang2017real,
  title={Real-time surgical tool tracking and pose estimation using a hybrid cylindrical marker},
  author={Zhang, Lin and Ye, Menglong and Chan, Po-Ling and Yang, Guang-Zhong},
  journal={International journal of computer assisted radiology and surgery},
  volume={12},
  pages={921--930},
  year={2017},
  publisher={Springer},
  abstract = {Purpose - To provide an integrated visualisation of intraoperative ultrasound and endoscopic images to facilitate
intraoperative guidance, real-time tracking of the ultrasound
probe is required. State-of-the-art methods are suitable for
planar targets while most of the laparoscopic ultrasound
probes are cylindrical objects. A tracking framework for
cylindrical objects with a large work space will improve the
usability of the intraoperative ultrasound guidance.
Methods - A hybrid marker design that combines circular
dots and chessboard vertices is proposed for facilitating
tracking cylindrical tools. The circular dots placed over the
curved surface are used for pose estimation. The chessboard
vertices are employed to provide additional information for
resolving the ambiguous pose problem due to the use of
planar model points under a monocular camera. Furthermore, temporal information between consecutive images is
considered to minimise tracking failures with real-time computational performance.
Results - Detailed validation confirms that our hybrid marker
provides a large working space for different tool sizes
(6–14mm in diameter). The tracking framework allows
translational movements between 40 and 185mm along the
depth direction and rotational motion around three local
orthogonal axes up to ±80◦. Comparative studies with the
current state of the art confirm that our approach outperforms
existing methods by providing nearly 100% detection rates
and accurate pose estimation with mean errors of 2.8mm and
0.72◦. The tracking algorithm runs at 20 frames per second
for 960 × 540 image resolution videos. Conclusion - Experiments show that the proposed hybrid
marker can be applied to a wide range of surgical tools with
superior detection rates and pose estimation accuracies. Both
the qualitative and quantitative results demonstrate that our
framework can be used not only for assisting intraoperative
ultrasound guidance but also for tracking general surgical
tools in MIS.},
  keywords = {}
}



@article{liu2023improved,
  title={Improved Identification for Point-Distributed Coded Targets with Self-Adaption and High Accuracy in Photogrammetry},
  author={Liu, Yang and Cui, Ximin and Wang, Qiang and Sun, Yanbiao},
  journal={Remote Sensing},
  volume={15},
  number={11},
  pages={2859},
  year={2023},
  publisher={MDPI},
  abstract = {A robust and effective method for the identification of point-distributed coded targets
(IPCT) in a video-simultaneous triangulation and resection system (V-STARS) was reported recently.
However, its limitations were the setting of critical parameters, it being non-adaptive, making
misidentifications in certain conditions, having low positioning precision, and its identification effect
being slightly inferior to that of the V-STARS. Aiming to address these shortcomings of IPCT, an
improved IPCT, named I-IPCT, with an adaptive binarization, a more precise ellipse-center localization, and especially an invariance of the point–line distance ratio (PLDR), was proposed. In the
process of edge extraction, the adaptive threshold Gaussian function was adopted to realize the
acquisition of an adaptive binarization threshold. For the process of center positioning of round
targets, the gray cubic weighted centroid algorithm was adopted to realize high-precision center
localization. In the template point recognition procedure, the invariant of the PLDR was used to
realize the determination of template points adaptively. In the decoding procedure, the invariant of
the PLDR was adopted to eliminate confusion. Experiments in indoor, outdoor, and unmanned aerial
vehicle (UAV) settings were carried out; meanwhile, sufficient comparisons with IPCT and V-STARS
were performed. The results show that the improvements can make the identification approximately
parameter-free and more accurate. Meanwhile, it presented a high three-dimensional measurement
precision in close-range photogrammetry. The improved IPCT performed equally well as the commercial software V-STARS on the whole and was slightly superior to it in the UAV test, in which it
provided a fantastic open solution using these kinds of coded targets and making it convenient for
researchers to freely apply the coded targets in many aspects, including UAV photogrammetry for
high-precision automatic image matching and three-dimensional real-scene reconstruction.},
  keywords = {}
}


@ARTICLE{wang2024cylindertag,
  author={Wang, Shaoan and Zhu, Mingzhu and Hu, Yaoqing and Li, Dongyue and Yuan, Fusong and Yu, Junzhi},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={CylinderTag: An Accurate and Flexible Marker for Cylinder-Shape Objects Pose Estimation Based on Projective Invariants}, 
  year={2024},
  volume={},
  number={},
  pages={1-15},
  abstract = {High-precision pose estimation based on visual markers has been a thriving research topic in the field of computer vision.
However, the suitability of traditional flat markers on curved objects is limited due to the diverse shapes of curved surfaces, which
hinders the development of high-precision pose estimation for curved objects. Therefore, this paper proposes a novel visual marker
called CylinderTag, which is designed for developable curved surfaces such as cylindrical surfaces. CylinderTag is a cyclic marker that
can be firmly attached to objects with a cylindrical shape. Leveraging the manifold assumption, the cross-ratio in projective invariance
is utilized for encoding in the direction of zero curvature on the surface. Additionally, to facilitate the usage of CylinderTag, we propose
a heuristic search-based marker generator and a high-performance recognizer as well. Moreover, an all-encompassing evaluation of
CylinderTag properties is conducted by means of extensive experimentation, covering detection rate, detection speed, dictionary size,
localization jitter, and pose estimation accuracy. CylinderTag showcases superior detection performance from varying view angles in
comparison to traditional visual markers, accompanied by higher localization accuracy. Furthermore, CylinderTag boasts real-time
detection capability and an extensive marker dictionary, offering enhanced versatility and practicality in a wide range of applications.
Experimental results demonstrate that the CylinderTag is a highly promising visual marker for use on cylindrical-like surfaces, thus
offering important guidance for future research on high-precision visual localization of cylinder-shaped objects. The code is available
at: https://github.com/wsakobe/CylinderTag.},
  keywords = {},
  doi={10.1109/TVCG.2024.3350901}}

@inproceedings{chen2023stackable,
author = {Chen, Max and Liang, Shano and Smith, Gillian},
title = {Stackable Music: A Marker-Based Augmented Reality Music Synthesis Game},
year = {2023},
isbn = {9798400700293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573382.3616071},
doi = {10.1145/3573382.3616071},
abstract = {Augmented reality (AR) allows the rendering of digital content on top of the physical space, which is a promising medium for tangible interaction. Marker-based AR is widely used thanks to its low cost and ease of integration, but the gameful aspect of manipulating the physical AR markers remains understudied. In this paper, we explored the stacking mechanics of transparent AR markers and described the creation of an AR music game called Stackable Music. Stackable Music can be developed, assembled, and set up at the home or office with a printer using several sheets of transparent film and a PC or mobile device with a camera.},
booktitle = {Companion Proceedings of the Annual Symposium on Computer-Human Interaction in Play},
pages = {22–28},
numpages = {7},
keywords = {},
location = {Stratford, ON, Canada},
series = {CHI PLAY Companion '23}
}

@inproceedings{norman2023actag,
  title={AcTag: Opti-Acoustic Fiducial Markers for Underwater Localization and Mapping},
  author={Norman, Kalin and Butterfield, Daniel and Mangelson, Joshua G},
  booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={9955--9962},
  year={2023},
  organization={IEEE},
  abstract = {Fiducial markers are important tools for robotic
navigation and imaging, enabling accurate localization and
tracking of objects in challenging environments. In this paper,
we present AcTag, a new fiducial marker design for use
underwater with imaging sonar and cameras, as well as a
method for the detection of AcTags within acoustic images.
High amounts of noise and a nonlinear projection model make
it difficult to use imaging sonar in autonomous localization
and mapping. In order to expand the use of imaging sonar
in autonomous underwater vehicles, our marker design and
detection algorithm for sonar images facilitate the identification
of four unique landmarks per tag, and provide relative range
and azimuth values to each landmark. We evaluate our marker
and detection algorithm with simulated and real-world sonar
data, reporting on the false positive and true positive rates,
as well as the estimated error for the range and azimuth
estimates per landmark. We also release an open-source library
for generating tag families and detecting the tags.},
  keywords = {}
}

@Article{neto2024tape,
AUTHOR = {Neto, Benedito S. R. and Araújo, Tiago D. O. and Meiguins, Bianchi S. and Santos, Carlos G. R.},
TITLE = {Tape-Shaped, Multiscale, and Continuous-Readable Fiducial Marker for Indoor Navigation and Localization Systems},
JOURNAL = {Sensors},
VOLUME = {24},
YEAR = {2024},
NUMBER = {14},
ARTICLE-NUMBER = {4605},
URL = {https://www.mdpi.com/1424-8220/24/14/4605},
ISSN = {1424-8220},
ABSTRACT = {The present study proposes a fiducial marker for location systems that uses computer vision. The marker employs a set of tape-shaped markers that facilitate their positioning in the environment, allowing continuous reading to cover the entire perimeter of the environment and making it possible to minimize interruptions in the location service. Because the marker is present throughout the perimeter of the environment, it presents hierarchical coding patterns that allow it to be robust against multiple detection scales. We implemented an application to help the user generate the markers with a floor plan image. We conducted two types of tests, one in a 3D simulation environment and one in a real-life environment with a smartphone. The tests made it possible to measure the performance of the tape-shaped marker with readings at multiple distances compared to ArUco, QRCode, and STag with detections at distances of 10 to 0.5 m. The localization tests in the 3D environment analyzed the time of marker detection during the journey from one room to another in positioning conditions (A) with the markers positioned at the baseboard of the wall, (B) with the markers positioned at camera height, and (C) with the marker positioned on the floor. The localization tests in real conditions allowed us to measure the time of detections in favorable conditions of detections, demonstrating that the tape-shaped-marker-detection algorithm is not yet robust against blurring but is robust against lighting variations, difficult angle displays, and partial occlusions. In both test environments, the marker allowed for detection at multiple scales, confirming its functionality.},
DOI = {10.3390/s24144605},
 
  keywords = {}
}
@article{wang2020acmarker,
  title={Acmarker: Acoustic camera-based fiducial marker system in underwater environment},
  author={Wang, Yusheng and Ji, Yonghoon and Liu, Dingyu and Tamura, Yusuke and Tsuchiya, Hiroshi and Yamashita, Atsushi and Asama, Hajime},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={4},
  pages={5018--5025},
  year={2020},
  publisher={IEEE},
  abstract = {ACMarker is an acoustic camera-based fiducial
marker system designed for underwater environments. Optical camera-based fiducial marker systems have been widely
used in computer vision and robotics applications such as
augmented reality (AR), camera calibration, and robot navigation. However, in underwater environments, the performance
of optical cameras is limited owing to water turbidity and
illumination conditions. Acoustic cameras, which are forwardlooking sonars, have been gradually applied in underwater
situations. They can acquire high-resolution images even in
turbid water with poor illumination. We propose methods
to recognize a simply designed marker and to estimate the
relative pose between the acoustic camera and the marker.
The proposed system can be applied to various underwater
tasks such as object tracking and localization of unmanned
underwater vehicles. Simulation and real experiments were
conducted to test the recognition of such markers and pose
estimation based on the markers.},
  keywords = {}
}
@Article{garcia2023fiducial,
AUTHOR = {García-Ruiz, Pablo and Romero-Ramirez, Francisco J. and Muñoz-Salinas, Rafael and Marín-Jiménez, Manuel J. and Medina-Carnicer, Rafael},
TITLE = {Fiducial Objects: Custom Design and Evaluation},
JOURNAL = {Sensors},
VOLUME = {23},
YEAR = {2023},
NUMBER = {24},
ARTICLE-NUMBER = {9649},
URL = {https://www.mdpi.com/1424-8220/23/24/9649},
PubMedID = {38139494},
ISSN = {1424-8220},
ABSTRACT = {Camera pose estimation is vital in fields like robotics, medical imaging, and augmented reality. Fiducial markers, specifically ArUco and Apriltag, are preferred for their efficiency. However, their accuracy and viewing angle are limited when used as single markers. Custom fiducial objects have been developed to address these limitations by attaching markers to 3D objects, enhancing visibility from multiple viewpoints and improving precision. Existing methods mainly use square markers on non-square object faces, leading to inefficient space use. This paper introduces a novel approach for creating fiducial objects with custom-shaped markers that optimize face coverage, enhancing space utilization and marker detectability at greater distances. Furthermore, we present a technique for the precise configuration estimation of these objects using multiviewpoint images. We provide the research community with our code, tutorials, and an application to facilitate the building and calibration of these objects. Our empirical analysis assesses the effectiveness of various fiducial objects for pose estimation across different conditions, such as noise levels, blur, and scale variations. The results suggest that our customized markers significantly outperform traditional square markers, marking a positive advancement in fiducial marker-based pose estimation methods.},
DOI = {10.3390/s23249649},
keywords = {}
}
@inproceedings{liang2024chic,
author = {Liang, Rong-Hao and van Iterson, Hannah and Krueger, Holly and Toeters, Marina and Feijs, Loe},
title = {Chic-Marker: Fashionably Fusing Fiducial Markers into Apparel and Accessories},
year = {2024},
isbn = {9798400704963},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639473.3665790},
doi = {10.1145/3639473.3665790},
abstract = {This paper proposes Chic-Marker, a fashionable approach to integrating square fiducial markers into apparel and accessories. While square fiducial markers have found widespread use in industrial and entertainment sectors for precise object identification and tracking, their integration into daily wearable items has been limited due to their conspicuous appearance. Previous efforts to conceal these markers using infrared-based methods have encountered obstacles, often requiring specialized equipment and lighting conditions. In this study, we propose a fresh perspective by embedding the markers within the timeless Pied-de-poule pattern, enhancing their visibility for tracking purposes and their fashion appeal. We use computational tools to design and manufacture functional garments using sublimation printing and traditional handcrafting techniques. Through rigorous technical evaluation and exploratory making, we analyze the characteristics of these markers and explore their material potential, offering valuable insights and guidelines for their seamless integration into future wearable applications.},
booktitle = {Proceedings of the 9th ACM Symposium on Computational Fabrication},
articleno = {1},
numpages = {15},
keywords = {},
location = {Aarhus, Denmark},
series = {SCF '24}
}
@article{claro2023artuga,
title = {ArTuga: A novel multimodal fiducial marker for aerial robotics},
journal = {Robotics and Autonomous Systems},
volume = {163},
pages = {104398},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104398},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000374},
author = {Rafael Marques Claro and Diogo Brandão Silva and Andry Maykol Pinto},
keywords = {},
abstract = {For Vertical Take-Off and Landing Unmanned Aerial Vehicles (VTOL UAVs) to operate autonomously and effectively, it is mandatory to endow them with precise landing abilities. The UAV has to be able to detect the landing target and to perform the landing maneuver without compromising its own safety and the integrity of its surroundings. However, current UAVs do not present the required robustness and reliability for precise landing in highly demanding scenarios, particularly due to their inadequacy to perform accordingly under challenging lighting and weather conditions, including in day and night operations. This work proposes a multimodal fiducial marker, named ArTuga (Augmented Reality Tag for Unmanned vision-Guided Aircraft), capable of being detected by an heterogeneous perception system for accurate and precise landing in challenging environments and daylight conditions. This research combines photometric and radiometric information by proposing a real-time multimodal fusion technique that ensures a robust and reliable detection of the landing target in severe environments. Experimental results using a real multicopter UAV show that the system was able to detect the proposed marker in adverse conditions (such as at different heights, with intense sunlight and in dark environments). The obtained average accuracy for position estimation at 1 m height was of 0.0060 m with a standard deviation of 0.0003 m. Precise landing tests obtained an average deviation of 0.027 m from the proposed marker, with a standard deviation of 0.026 m. These results demonstrate the relevance of the proposed system for the precise landing in adverse conditions, such as in day and night operations with harsh weather conditions.}
}

@article{digiacomo2021mechatag,
  title={MechaTag: A mechanical fiducial marker and the detection algorithm},
  author={Digiacomo, Francesca and Bologna, Francesco and Inglese, Francesco and Stefanini, Cesare and Milazzo, Mario},
  journal={Journal of Intelligent \& Robotic Systems},
  volume={103},
  number={3},
  pages={46},
  year={2021},
  publisher={Springer},
  abstract = {Fiducial markers are fundamental components of many computer vision systems that help, through their unique features (e.g.,
shape, color), a fast localization of spatial objects in unstructured scenarios. They find applications in many scientific and
industrial fields, such as augmented reality, human-robot interaction, and robot navigation. In order to overcome the limitations
of traditional paper-printed fiducial markers (i.e. deformability of the paper surface, incompatibility with industrial and harsh
environments, complexity of the shape to reproduce directly on the piece), we aim at exploiting existing, or additionally
fabricated, structural features on rigid bodies (e.g., holes), developing a fiducial mechanical marker system called MechaTag.
Our system, endowed with a dedicated algorithm, is able to minimize recognition errors and to improve repeatability also in case
of ill boundary conditions (e.g., partial illumination). We assess MechaTag in a pilot study, achieving a robustness of fiducial
marker recognition above 95% in different environment conditions and position configurations. The pilot study was conducted
by guiding a robotic platform in different poses in order to experiment with a wide range of working conditions. Our results make
MechaTag a reliable fiducial marker system for a wide range of robotic applications in harsh industrial environments without
losing accuracy of recognition due to the shape and material.},
  keywords = {}
}

@inproceedings{dogan2023structcode,
  title={StructCode: Leveraging Fabrication Artifacts to Store Data in Laser-Cut Objects},
  author={Dogan, Mustafa Doga and Chan, Vivian Hsinyueh and Qi, Richard and Tang, Grace and Roumen, Thijs and Mueller, Stefanie},
  booktitle={Proceedings of the 8th ACM Symposium on Computational Fabrication},
  pages={1--13},
  year={2023},
  abstract = {We introduce StructCode, a technique to store machine-readable
data in laser-cut objects using their fabrication artifacts. StructCode
modifies the lengths of laser-cut finger joints and/or living hinges to
represent bits of information without introducing additional parts
or materials. We demonstrate StructCode through use cases for
augmenting laser-cut objects with data such as labels, instructions,
and narration. We present and evaluate a tag decoding pipeline that
is robust to various backgrounds, viewing angles, and wood types.
In our mechanical evaluation, we show that StructCodes preserve
the structural integrity of laser-cut objects.},
  keywords = {}
}


@article{grinchuk2016learnable,
  title={Learnable visual markers},
  author={Grinchuk, Oleg and Lebedev, Vadim and Lempitsky, Victor},
  journal={Advances In Neural Information Processing Systems},
  volume={29},
  year={2016},
  abstract = {We propose a new approach to designing visual markers (analogous to QR-codes,
markers for augmented reality, and robotic fiducial tags) based on the advances
in deep generative networks. In our approach, the markers are obtained as color
images synthesized by a deep network from input bit strings, whereas another
deep network is trained to recover the bit strings back from the photos of these
markers. The two networks are trained simultaneously in a joint backpropagation
process that takes characteristic photometric and geometric distortions associated
with marker fabrication and marker scanning into account. Additionally, a stylization loss based on statistics of activations in a pretrained classification network
can be inserted into the learning in order to shift the marker appearance towards
some texture prototype. In the experiments, we demonstrate that the markers obtained using our approach are capable of retaining bit strings that are long enough
to be practical. The ability to automatically adapt markers according to the usage
scenario and the desired capacity as well as the ability to combine information
encoding with artistic stylization are the unique properties of our approach. As
a byproduct, our approach provides an insight on the structure of patterns that
are most suitable for recognition by ConvNets and on their ability to distinguish
composite patterns.},
  keywords = {}
}


@inproceedings{lee2014new,
  title={A new approach of detection and recognition for artificial landmarks from noisy acoustic images},
  author={Lee, Yeongjun and Kim, Tae Gyun and Choi, Hyun-Taek},
  booktitle={Robot Intelligence Technology and Applications 2: Results from the 2nd International Conference on Robot Intelligence Technology and Applications},
  pages={851--858},
  year={2014},
  organization={Springer},
  abstract = {This paper presents a framework for underwater object detection and recognition using acoustic image from an imaging sonar. It is difficult to get a stable acoustic image from any type object because of characteristic of ultrason- ic wave. To overcome the difficulties, the framework consists of the selection of candidate, the recognition, and tracking of identified object. In selection of candidate phase, we select candidate as possible objects using an initial image processing and get rid of noise or discontinuous object using a probability based method in series of images. The selected candidate is processed in adaptive lo- cal image processing and recognition using shape matrix recognition method. Identified object in previous phase is tracked without selection of candidate, and recognition phase. We perform two simple tests for the verification of each phase and whole framework operability.},
  keywords = {}
}

@inproceedings{saito2007indoor,
  title={Indoor marker-based localization using coded seamless pattern for interior decoration},
  author={Saito, Shigeru and Hiyama, Atsushi and Tanikawa, Tomohiro and Hirose, Michitaka},
  booktitle={2007 IEEE Virtual Reality Conference},
  pages={67--74},
  year={2007},
  organization={IEEE},
  abstract = {Because marker-based position tracking system is inexpensive
and easy to use, it has the potential to make the system more
feasible for homes or businesses and broaden the current suite of
augmented reality (AR) techniques. To apply marker-based
systems to homes or businesses, blending markers with
environments naturally is important. Our innovative approach to
marker-based 3D position tracking uses seamless patterns
encrypted with positional data. Although users can obtain 3D
positional data by processing marker images similar to many
existing marker-based systems, our markers are designed with
interior decoration in mind. That way they can be installed in
walls, floors, or ceilings. Unlike existing systems whose fiducial
markers were designed first and foremost to be processed by
computers, ours are visually attractive. By integrating positional
information within the interior design, our system enables users to
enjoy the benefits of position tracking without being constantly
aware of the system’s presence.
We developed a method for making patterns in which
positional information is encrypted and a method for calculating
the 3D position of a user by decoding those patterns. We then
constructed a system using three patterns that were made by the
proposed method and evaluated that system.},
  keywords = {}
}

@article{wagner2007artoolkitplus,
  title={Artoolkitplus for pose tracking on mobile devices},
  author={Wagner, Daniel and Schmalstieg, Dieter},
  year={2007},
  publisher={Citeseer},
  abstract = {In this paper we present ARToolKitPlus, a
successor to the popular ARToolKit pose tracking library.
ARToolKitPlus has been optimized and extended for the
usage on mobile devices such as smartphones, PDAs and
Ultra Mobile PCs (UMPCs). We explain the need and
specific requirements of pose tracking on mobile devices
and how we met those requirements. To prove the
applicability we performed an extensive benchmark series
on a broad range of off-the-shelf handhelds.},
  keywords = {}
}
